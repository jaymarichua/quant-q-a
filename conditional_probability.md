<h5>Conditional Probability</h5>

Quick mathematics questions in probability mainly involve Bayes' theorem and Expected Value (EV).

<h6>Bayes' theorem (2nd form)</h6>

$$P_E(H) = P(H)P_H(E) / [P(H)P_H(E) + P(~H)P_{~H}(E)]$$

<h6>Expected Utility</h6>

$$EU(A)=\sum_{oâˆˆO} P_A(o)U(o)$$

<h6>Stanford Encyclopedia of Philosophy</h6>

Bayes' Theorem

`https://plato.stanford.edu/entries/bayes-theorem/`

Conditional Probability and Expected Utility Theory

`https://plato.stanford.edu/entries/rationality-normative-utility/`

<h6>Bayes' Theorem and Machine Learning</h6>

Many modern machine learning techniques rely on Bayes' theorem; a way to update beliefs upon discovery of new information.

A memorable quote from last year on X, was a conditional "If you are true Bayesian,..."; which prompted revisiting my understanding of Bayes' theorem. I found an in-depth summary from Stanford: `https://plato.stanford.edu/entries/bayes-theorem/` and `https://plato.stanford.edu/entries/rationality-normative-utility/`.

Level 1 understanding: Machine learning involves updating beliefs upon new information utilising on Bayes' theorem. For some reason, the legal page has a practical discussion `https://plato.stanford.edu/entries/legal-probabilism/#BayeNetwForLegaAppl` as to how Bayesian nets are used for induction and leads easily to the discussion topic of induction itself `https://plato.stanford.edu/entries/induction-problem/`.

<h5>References</h5>

_Ref._ _Conditional Probability. Brilliant.org. Retrieved 02:45, January 24, 2024, from https://brilliant.org/wiki/conditional-probability/_

_Ref._ _Bayes' Theorem and Conditional Probability. Brilliant.org. Retrieved 02:48, January 24, 2024, from https://brilliant.org/wiki/bayes-theorem/_

_Ref._ _Bayes' theorem, the geometry of changing beliefs. 3Blue1Brown. Retrieved 02:53, January 24, 2024, from https://www.youtube.com/watch?v=HZGCoVF3YvM_

_Ref._ _Conditional Probability. Yale. Retrieved 05:36, January 27, 2024, from http://www.stat.yale.edu/Courses/1997-98/101/condprob.htm_
